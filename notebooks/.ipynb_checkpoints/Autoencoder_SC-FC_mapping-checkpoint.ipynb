{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConnectomeTransformer:\n",
    "    \n",
    "    def __init__(self, n_hidden, alpha = 0.001, l1_ratio = 0.3, lambd = 0.5):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.n_hidden = n_hidden\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "        self.lambd = lambd\n",
    "    \n",
    "    def create_placeholders(self, data, target):\n",
    "        \"\"\"\n",
    "        Create placeholders for data, assuming that the data is provided\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = tf.placeholder(name = \"X\", shape=data.shape, dtype=tf.float32)\n",
    "        self.target = tf.placeholder(name = \"target\", shape = target.shape, dtype=tf.float32)\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        \n",
    "        self.parameters = {}\n",
    "        \n",
    "        # Autoencoder\n",
    "        self.parameters['W0'] = tf.get_variable(\n",
    "            \"W0\", \n",
    "            [self.X.shape[1], self.n_hidden], \n",
    "            initializer = tf.contrib.layers.xavier_initializer(seed = 1), \n",
    "            regularizer = tf.contrib.layers.l2_regularizer(scale=self.alpha, scope=None)   \n",
    "        )\n",
    "        self.parameters['b0'] = tf.get_variable(\n",
    "            \"b0\", \n",
    "            [self.X.shape[0],1], \n",
    "            initializer = tf.zeros_initializer()\n",
    "        )\n",
    "        self.parameters['b1'] = tf.get_variable(\n",
    "            \"b1\", \n",
    "            [self.X.shape[0], 1], \n",
    "            initializer = tf.zeros_initializer()\n",
    "        )\n",
    "        \n",
    "    def forward(self):\n",
    "        \n",
    "        # Autoencoder\n",
    "        self.parameters['A0'] = tf.matmul(self.X, self.parameters['W0']) + self.parameters['b0']\n",
    "        self.X_prime = tf.matmul(self.parameters['A0'], tf.transpose(self.parameters['W0'])) + self.parameters['b1']\n",
    "\n",
    "    def compute_cost(self):\n",
    "        \n",
    "        l1_regularizer = tf.contrib.layers.l1_regularizer(\n",
    "           scale=self.alpha, scope=None\n",
    "        )\n",
    "        \n",
    "        l2_regularizer = tf.contrib.layers.l2_regularizer(\n",
    "           scale=self.alpha, scope=None\n",
    "        )\n",
    "        \n",
    "        weights = [v for v in tf.trainable_variables() if 'b' not in v.name] # all vars of your graph\n",
    "        \n",
    "        l1_penalty = tf.contrib.layers.apply_regularization(l1_regularizer, weights)\n",
    "        l2_penalty = tf.contrib.layers.apply_regularization(l2_regularizer, weights)\n",
    "        \n",
    "        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        \n",
    "        self.cost_ = tf.losses.mean_squared_error(self.target, self.X_prime)\n",
    "        \n",
    "    def fit(self, data = None,\n",
    "            target = None,\n",
    "            n_epochs = 10, \n",
    "            learning_rate = 0.0001,\n",
    "            minibatch_size = 100):\n",
    "        \n",
    "        assert data is not None, \"You need to provide data.\"\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        self.create_placeholders(data, target)\n",
    "        self.initialize_parameters()\n",
    "        \n",
    "        self.forward()\n",
    "        self.compute_cost()\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.cost_)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        tf.set_random_seed(1)\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run(init)\n",
    "            for epoch in range(n_epochs):\n",
    "                _ , cost = sess.run([optimizer, self.cost_], feed_dict={self.X: data, self.target: target})\n",
    "                if epoch % 100 == 0:\n",
    "                    print(\"Epoch %d, cost: %.5f\" % (epoch, cost))\n",
    "            \n",
    "            self.coef_ = {}\n",
    "            self.coef_['W0'] = self.parameters['W0'].eval()\n",
    "            \n",
    "            self.X_prime = self.X_prime.eval(feed_dict={self.X: data})\n",
    "            \n",
    "            \"\"\"\n",
    "            self.predicted_ = tf.argmax(tf.nn.softmax(self.parameters['pred_labeled']), axis=1).eval(feed_dict={\n",
    "                                                                       self.X_labeled: data_labeled,\n",
    "                                                                       self.Y: y})\n",
    "            \n",
    "            correct_prediction = tf.equal(tf.argmax(self.parameters['pred_labeled'], axis = 1), self.Y)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "            print (\"Train Accuracy:\", accuracy.eval({self.X_labeled: data_labeled, self.Y: y}))\n",
    "            if data_test is not None and y_test is not None:\n",
    "                print (\"Test Accuracy:\", accuracy.eval({self.X_labeled: data_test, self.Y: y_test}))\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc33 = np.loadtxt('../scratch/hcp_l2k8_data/100307/HCP_SC_avg_sc33.txt')\n",
    "np.fill_diagonal(sc33, 0)\n",
    "sc33 = (sc33 + sc33.T)/2\n",
    "fc33 = np.loadtxt('../scratch/hcp_l2k8_data/100307/HCP_FC_avg_sc33.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.matshow(sc33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ae1 = ConnectomeTransformer(n_hidden=50)\n",
    "ae1.fit(data = sc33, target = fc33, n_epochs = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "ax.matshow(sc33)\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "ax.matshow(fc33)\n",
    "\n",
    "ax = fig.add_subplot(223)\n",
    "ax.matshow(ae1.X_prime)\n",
    "\n",
    "ax = fig.add_subplot(224)\n",
    "ax.scatter(ae1.X_prime, fc33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('../scratch/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.corrcoef(fc33.ravel(), ae1.X_prime.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
